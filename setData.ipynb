{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/nfs/datasets/mscoco2014\"\n",
    "name = \"coco_caption_karpathy_train\"\n",
    "names = [\"coco_caption_karpathy_train\", \"coco_caption_karpathy_test\", \"coco_caption_karpathy_val\", \"coco_caption_karpathy_restval\"]\n",
    "# tables = [\n",
    "#                 pa.ipc.RecordBatchFileReader(\n",
    "#                     pa.memory_map(f\"{data_dir}/{name}.arrow\", \"r\")\n",
    "#                 ).read_all()\n",
    "#                 for name in names\n",
    "#                 if os.path.isfile(f\"{data_dir}/{name}.arrow\")\n",
    "#             ]\n",
    "\n",
    "table = pa.ipc.open_file(\"/data/nfs/datasets/mscoco2014/coco_caption_karpathy_test.arrow\").read_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image  \\\n",
      "0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "1  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "2  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "3  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "4  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "\n",
      "                                             caption  \\\n",
      "0  [A traffic light over a street surrounded by t...   \n",
      "1  [A pot holds several large purple flowers, and...   \n",
      "2  [An elephant with a man and three children on ...   \n",
      "3  [Two women in the kitchen with a plate of spag...   \n",
      "4  [This wire metal rack holds several pairs of s...   \n",
      "\n",
      "                        image_id split  \n",
      "0  COCO_val2014_000000000359.jpg  test  \n",
      "1  COCO_val2014_000000191240.jpg  test  \n",
      "2  COCO_val2014_000000000974.jpg  test  \n",
      "3  COCO_val2014_000000396691.jpg  test  \n",
      "4  COCO_val2014_000000000042.jpg  test  \n"
     ]
    }
   ],
   "source": [
    "print(table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "import ipdb\n",
    "\n",
    "\n",
    "\n",
    "from vilt.modules import ViLTransformerSS\n",
    "\n",
    "from vilt.modules.objectives import cost_matrix_cosine, ipot\n",
    "from vilt.transforms import pixelbert_transform\n",
    "from vilt.datamodules.datamodule_base import get_pretrained_tokenizer\n",
    "\n",
    "_config = {'exp_name': 'vilt', 'seed': 0, 'datasets': ['coco', 'vg', 'sbu', 'gcc'], 'loss_names': {'itm': 1, 'mlm': 1, 'mpp': 0, 'vqa': 0, 'nlvr2': 0, 'irtr': 0}, 'batch_size': 4096, 'train_transform_keys': ['pixelbert'], 'val_transform_keys': ['pixelbert'], 'image_size': 384, 'max_image_len': -1, 'patch_size': 32, 'draw_false_image': 1, 'image_only': False, 'vqav2_label_size': 3129, 'max_text_len': 40, 'tokenizer': 'bert-base-uncased', 'vocab_size': 30522, 'whole_word_masking': False, 'mlm_prob': 0.15, 'draw_false_text': 0, 'vit': 'vit_base_patch32_384', 'hidden_size': 768, 'num_heads': 12, 'num_layers': 12, 'mlp_ratio': 4, 'drop_rate': 0.1, 'optim_type': 'adamw', 'learning_rate': 0.0001, 'weight_decay': 0.01, 'decay_power': 1, 'max_epoch': 100, 'max_steps': 25000, 'warmup_steps': 2500, 'end_lr': 0, 'lr_mult': 1, 'get_recall_metric': False, 'resume_from': None, 'fast_dev_run': False, 'val_check_interval': 1.0, 'test_only': False, 'data_root': '', 'log_dir': 'result', 'per_gpu_batchsize': 0, 'num_gpus': 0, 'num_nodes': 1, 'load_path': 'weights/vilt_200k_mlm_itm.ckpt', 'num_workers': 8, 'precision': 16}\n",
    "_config = copy.deepcopy(_config)\n",
    "\n",
    "\n",
    "loss_names = {\n",
    "    \"itm\": 0,\n",
    "    \"mlm\": 0.5,\n",
    "    \"mpp\": 0,\n",
    "    \"vqa\": 0,\n",
    "    \"imgcls\": 0,\n",
    "    \"nlvr2\": 0,\n",
    "    \"irtr\": 0,\n",
    "    \"arc\": 0,\n",
    "}\n",
    "tokenizer = get_pretrained_tokenizer(_config[\"tokenizer\"])\n",
    "\n",
    "\n",
    "_config.update(\n",
    "    {\n",
    "        \"loss_names\": loss_names,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = ViLTransformerSS(_config)\n",
    "model.setup(\"test\")\n",
    "#开启评估模式\n",
    "model.eval()\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if _config[\"num_gpus\"] > 0 else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "print(\"加载模型\")\n",
    "data_dir = \"/data/nfs/datasets/mscoco2014\"\n",
    "name = \"coco_caption_karpathy_train\"\n",
    "names = [\"coco_caption_karpathy_train\", \"coco_caption_karpathy_test\", \"coco_caption_karpathy_val\", \"coco_caption_karpathy_restval\"]\n",
    "# tables = [\n",
    "#                 pa.ipc.RecordBatchFileReader(\n",
    "#                     pa.memory_map(f\"{data_dir}/{name}.arrow\", \"r\")\n",
    "#                 ).read_all()\n",
    "#                 for name in names\n",
    "#                 if os.path.isfile(f\"{data_dir}/{name}.arrow\")\n",
    "#             ]\n",
    "\n",
    "table = pa.ipc.open_file(\"/data/nfs/datasets/mscoco2014/coco_caption_karpathy_test.arrow\").read_pandas()\n",
    "print(\"加载dataset\")\n",
    "def infer(image, mp_text):\n",
    "    try:\n",
    "        # res = requests.get(url)\n",
    "        # image = Image.open(io.BytesIO(res.content)).convert(\"RGB\")\n",
    "        image = Image.open(io.BytesIO(image)).convert(\"RGB\")\n",
    "        img = pixelbert_transform(size=384)(image)\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        # 完成img的预处理\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    batch = {\"text\": [\"\"], \"image\": [None]}\n",
    "    tl = len(re.findall(\"\\[MASK\\]\", mp_text))\n",
    "    inferred_token = [mp_text]\n",
    "    batch[\"image\"][0] = img\n",
    "\n",
    "\n",
    "    selected_token = \"\"\n",
    "    encoded = tokenizer(inferred_token)\n",
    "    # 完成text的预处理\n",
    "\n",
    "    \n",
    "    batch[\"text\"] = inferred_token\n",
    "    batch[\"text_ids\"] = torch.tensor(encoded[\"input_ids\"]).to(device)\n",
    "    batch[\"text_labels\"] = torch.tensor(encoded[\"input_ids\"]).to(device)\n",
    "    batch[\"text_masks\"] = torch.tensor(encoded[\"attention_mask\"]).to(device)\n",
    "    infer = model(batch)\n",
    "    \n",
    "    txt_emb, img_emb = infer[\"text_feats\"], infer[\"image_feats\"]\n",
    "\n",
    "    print(infer[\"cls_feats\"].shape)\n",
    "\n",
    "            \n",
    "        \n",
    "    return infer[\"raw_cls_feats\"]\n",
    "\n",
    "dataset_root=\"/home/zzzqi/ViLT/dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import numpy as np\n",
    "\n",
    "zh_model = StanfordCoreNLP(r'/home/zzzqi/ViLT/nlp/stanford-corenlp-full-2018-10-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToHeadAdj(textEn):\n",
    "\n",
    "    s_zh = textEn\n",
    "    dep_zh = zh_model.dependency_parse(s_zh)\n",
    "    '''查找根结点对应的索引'''\n",
    "    root_index=[]\n",
    "    for i in range(len(dep_zh)):\n",
    "        if dep_zh[i][0]=='ROOT':\n",
    "            root_index.append(i)\n",
    "\n",
    "    '''修改依存关系三元组'''\n",
    "    new_dep_outputs=[]\n",
    "    for i in range(len(dep_zh)):\n",
    "        for index in root_index:\n",
    "            if i+1>index:\n",
    "                tag=index\n",
    "\n",
    "        if dep_zh[i][0]=='ROOT':\t\n",
    "            dep_output=(dep_zh[i][0],dep_zh[i][1],dep_zh[i][2]+tag)\n",
    "        else:\n",
    "            dep_output = (dep_zh[i][0], dep_zh[i][1] + tag, dep_zh[i][2] + tag)\n",
    "        new_dep_outputs.append(dep_output)\n",
    "\n",
    "    head_list = []\n",
    "    tokens = zh_model.word_tokenize(s_zh)\n",
    "    # 求解headlist\n",
    "    for i in range(len(tokens)):\n",
    "        for dep_output in new_dep_outputs:\n",
    "            if dep_output[-1] == i + 1:\n",
    "                head_list.append(int(dep_output[1]))\n",
    "\n",
    "\n",
    "    # 得出邻接矩阵\n",
    "    # def head_to_adj(head,max_sent_len):\n",
    "    #     ret = np.zeros((max_sent_len, max_sent_len), dtype=np.float32)\n",
    "    #     for i in range(len(head)):\n",
    "    #         j=head[i]\n",
    "    #         if j!=0:\n",
    "    #             ret[i,j-1]=1\n",
    "    #             ret[j-1,i]=1\n",
    "\n",
    "    #     return ret\n",
    "    \n",
    "    ret = np.zeros((20,20))\n",
    "    for i in range(len(head_list)):\n",
    "        j=head_list[i]\n",
    "        if j!=0:\n",
    "            ret[i,j-1]=1\n",
    "            ret[j-1,i]=1\n",
    "\n",
    "    # result = head_to_adj(head_list, 20)\n",
    "    # print(result.reshape(1,400))\n",
    "    return ret.reshape(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "ret = textToHeadAdj('a display of flowers growing out and over the retaining wall in front of cottages on a cloudy day.')\n",
    "\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list = []\n",
    "for row in table.itertuples():\n",
    "  \n",
    "    if(row[0]==1):\n",
    "        img = row[1]\n",
    "        text = (row[2])[0]\n",
    "    \n",
    "        raw_cls_feature = infer(img, text)\n",
    "        tempList = raw_cls_feature.detach().numpy().tolist()\n",
    "        dep_tree = textToHeadAdj(text)\n",
    "        tempList.append(dep_tree.tolist())\n",
    "        # print(raw_cls_feature)\n",
    "        list.append(tempList)\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(\n",
    "            list, columns=[\"raw_cls_feature\", \"dep_tree_adj\"],\n",
    "        )\n",
    "\n",
    "table = pa.Table.from_pandas(dataframe)\n",
    "os.makedirs(dataset_root, exist_ok=True)\n",
    "with pa.OSFile(\n",
    "    f\"{dataset_root}/coco_caption_karpathy_test.arrow\", \"wb\"\n",
    ") as sink:\n",
    "    with pa.RecordBatchFileWriter(sink, table.schema) as writer:\n",
    "        writer.write_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                image  \\\n",
      "0   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "1   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "2   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "3   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "4   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "5   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "6   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "7   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "8   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "9   b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "10  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "11  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "12  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "13  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "14  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "15  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "16  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "17  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "18  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "19  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "20  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "21  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "22  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "23  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "24  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "25  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "26  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "27  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
      "\n",
      "                                              caption  \\\n",
      "0   [A woman standing over a sheet cake sitting on...   \n",
      "1   [A coffee table sits in the middle of a living...   \n",
      "2   [A messy and unmade bed and a red chair, A soi...   \n",
      "3   [A teddy bear lying on the ground by some leav...   \n",
      "4   [A toilet seat sits on top of a hole in the gr...   \n",
      "5   [A person is skiing with ropes tied to a broke...   \n",
      "6   [A kitchen area with two refrigerators and a m...   \n",
      "7   [A pond with two ducks swimming on top of it.,...   \n",
      "8   [A young boy who is batting at a baseball game...   \n",
      "9   [Two women in the kitchen with a plate of spag...   \n",
      "10  [A young man wearing black attire and a flower...   \n",
      "11  [A cat sitting on the back of a bench while lo...   \n",
      "12  [A pot holds several large purple flowers, and...   \n",
      "13  [An elephant with a man and three children on ...   \n",
      "14  [A baseball player holding a bat while standin...   \n",
      "15  [A surfer is on his board in the middle of an ...   \n",
      "16  [A little boy brushes his teeth and looks at t...   \n",
      "17  [A traffic light over a street surrounded by t...   \n",
      "18  [A towel that is on a rack in a bathroom., A w...   \n",
      "19  [A baby in high chair with bib and cake., Two ...   \n",
      "20  [A yellow and white cat sitting next to a book...   \n",
      "21  [a sandwich in a plastic food basket on a tabl...   \n",
      "22  [This wire metal rack holds several pairs of s...   \n",
      "23  [Giraffes are walking together on a very dry t...   \n",
      "24  [A smart phone being held up in front of a lap...   \n",
      "25  [a close up of food on a plate on a table, A p...   \n",
      "26  [A train traveling down train tracks next to a...   \n",
      "27  [Photo taken in a car of the television on the...   \n",
      "\n",
      "                         image_id split  \n",
      "0   COCO_val2014_000000001180.jpg  test  \n",
      "1   COCO_val2014_000000000711.jpg  test  \n",
      "2   COCO_val2014_000000190648.jpg  test  \n",
      "3   COCO_val2014_000000190783.jpg  test  \n",
      "4   COCO_val2014_000000000636.jpg  test  \n",
      "5   COCO_val2014_000000396542.jpg  test  \n",
      "6   COCO_val2014_000000397404.jpg  test  \n",
      "7   COCO_val2014_000000396779.jpg  test  \n",
      "8   COCO_val2014_000000397042.jpg  test  \n",
      "9   COCO_val2014_000000396691.jpg  test  \n",
      "10  COCO_val2014_000000001146.jpg  test  \n",
      "11  COCO_val2014_000000397045.jpg  test  \n",
      "12  COCO_val2014_000000191240.jpg  test  \n",
      "13  COCO_val2014_000000000974.jpg  test  \n",
      "14  COCO_val2014_000000191096.jpg  test  \n",
      "15  COCO_val2014_000000396693.jpg  test  \n",
      "16  COCO_val2014_000000190595.jpg  test  \n",
      "17  COCO_val2014_000000000359.jpg  test  \n",
      "18  COCO_val2014_000000190705.jpg  test  \n",
      "19  COCO_val2014_000000001290.jpg  test  \n",
      "20  COCO_val2014_000000190690.jpg  test  \n",
      "21  COCO_val2014_000000000810.jpg  test  \n",
      "22  COCO_val2014_000000000042.jpg  test  \n",
      "23  COCO_val2014_000000191390.jpg  test  \n",
      "24  COCO_val2014_000000191069.jpg  test  \n",
      "25  COCO_val2014_000000397041.jpg  test  \n",
      "26  COCO_val2014_000000396692.jpg  test  \n",
      "27  COCO_val2014_000000191842.jpg  test  \n"
     ]
    }
   ],
   "source": [
    "test = pa.ipc.open_file(\"/home/zzzqi/ViLT/dataset/mscoco2014mini/coco_caption_karpathy_test.arrow\").read_pandas()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for row in table.itertuples():\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('vilt3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e488c7a4fce4353dfd1aaded5f2cd88c4c070e8a1e29701a368e5074db371aac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
